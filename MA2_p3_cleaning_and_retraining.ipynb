{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVhlwc2YyLTqxOoYrLGfxp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdeepbanerjee-git/Data_Augmentation_LLM/blob/main/MA2_p3_cleaning_and_retraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook, we saw how to generate synthetic instances of spam messages similar to our false negative cases. Now we will take the llm output, clean it and use it augment the training data and retrain our model."
      ],
      "metadata": {
        "id": "5sHKNn22pj3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "kETS6Wk4pe0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_responses(file_path, start_tag=\"<START>\", end_tag=\"<END>\"):\n",
        "    \"\"\"\n",
        "    - We will read in the llm out as text file a text file\n",
        "    - extract lines situated between lines containing <START> and <END> markers.\n",
        "    \"\"\"\n",
        "\n",
        "    extracted_lines = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        capture = False\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if start_tag in line:\n",
        "                capture = True\n",
        "                extracted_lines.append(line.replace(start_tag, '').strip())\n",
        "            elif end_tag in line:\n",
        "                capture = False\n",
        "                extracted_lines[-1] += ' ' + line.replace(end_tag, '').strip()\n",
        "            elif capture:\n",
        "                extracted_lines[-1] += ' ' + line.strip()\n",
        "\n",
        "    return extracted_lines"
      ],
      "metadata": {
        "id": "6D61pQbtpex0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/llm_output_final.txt\"\n",
        "extracted_response = extract_responses(file_path = file_path, start_tag=\"<START>\", end_tag=\"<END>\")"
      ],
      "metadata": {
        "id": "0_flB9R5pevC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process(extracted_lines):\n",
        "    \"\"\"\n",
        "    - remove the list entry that contains the '<|user|>' or  '<|end|>' tags\n",
        "    - remove special tags like '<END>', '####', '<|assistant|> '\n",
        "    - deduplicate list entries (there is a lot of duplicated entries due to hallucination)\n",
        "\n",
        "    Note: these post processing steps can vary based on the prompt and the model\n",
        "    \"\"\"\n",
        "\n",
        "    processed_lines = []\n",
        "    seen_lines = set()\n",
        "\n",
        "    for line in extracted_lines:\n",
        "        # Remove entries that contain both <START> and <END> tags\n",
        "        if '<|user|>' in line or '<|end|>' in line:\n",
        "            continue\n",
        "\n",
        "        # Remove special tags like '<|assistant|>', '<END>', '####'\n",
        "        line = line.replace('<|assistant|>', '').replace('<END>', '').replace('####', '').strip()\n",
        "\n",
        "        # Skip if the line is empty\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Deduplicate entries\n",
        "        if line not in seen_lines:\n",
        "            seen_lines.add(line)\n",
        "            processed_lines.append(line)\n",
        "\n",
        "    return processed_lines"
      ],
      "metadata": {
        "id": "GJp5Pm_epeqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean llm output\n",
        "cleaned_lines = post_process(extracted_lines = extracted_response)\n",
        "\n",
        "# save the cleaned output\n",
        "file_path = '/content/cleaned_llm_output.txt'\n",
        "with open(file_path, 'w') as file:\n",
        "  for lines in cleaned_lines:\n",
        "    file.write(lines + '\\n')\n"
      ],
      "metadata": {
        "id": "AhONRQPKpenq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to read\n",
        "file_path = '/content/cleaned_llm_output.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "  lines = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "print(\"total examples\", len(lines))\n",
        "\n",
        "import pprint as pp\n",
        "pp.pprint(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwtIDisCpekm",
        "outputId": "32cb2bd6-3f27-48ca-f752-373684b016d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total examples 41\n",
            "[\"Hey there! I've got a once-in-a-lifetime deal for you! Click on this link \"\n",
            " \"and get your hands on a rare, limited edition collector's item. Hurry up, \"\n",
            " \"this offer won't last forever!\",\n",
            " \"Attention all O2 users! You've been selected for an exclusive offer. Click \"\n",
            " \"on this link and claim your free upgrade to the premium plan. Don't miss out \"\n",
            " 'on this amazing opportunity!',\n",
            " \"URGENT! You've been chosen to receive a special gift from your favorite \"\n",
            " 'celebrity. Click on this link to claim your prize and get a sneak peek into '\n",
            " 'their personal life. This is a once-in-a-lifetime opportunity!',\n",
            " \"Hello, dear friend! I'm reaching out to you with a special offer. Click on \"\n",
            " 'this link and get a free vacation package to your dream destination. Hurry '\n",
            " \"up, this offer won't last forever!\",\n",
            " \"Attention all Vodafone users! You've been selected for a special offer. \"\n",
            " 'Click on this link and claim your free subscription to our premium music '\n",
            " \"streaming service. Don't miss out on this amazing opportunity!\",\n",
            " \"Attention all O2 users! You've been selected for a special offer. Click on \"\n",
            " \"this link and claim your free upgrade to the premium plan. Don't miss out on \"\n",
            " 'this amazing opportunity!',\n",
            " \"Hey there! I've got a hot deal for you. Text me now and I'll send you a \"\n",
            " \"free, unlimited, and uncensored video of me in all my glory. Don't miss out!\",\n",
            " \"Are you ready for the ultimate fantasy? Text me and I'll take you on a wild \"\n",
            " \"ride of passion and pleasure. I promise to be the best lover you've ever \"\n",
            " \"had. Don't hesitate, text me now!\",\n",
            " \"I'm a wealthy businessman with a secret. Text me and I'll reveal all. I'll \"\n",
            " \"give you a share of my fortune if you're willing to take the risk. Don't let \"\n",
            " 'this opportunity slip away!',\n",
            " \"I'm a famous model with millions of fans. Text me and I'll send you a \"\n",
            " \"private video of me posing in the latest fashion trends. You'll be the envy \"\n",
            " \"of all your friends. Don't wait, text me now!\",\n",
            " \"I'm a successful entrepreneur with a hidden agenda. Text me and I'll offer \"\n",
            " \"you a chance to join my exclusive club. You'll have access to all my secrets \"\n",
            " \"and resources. Don't miss out on this once-in-a-lifetime opportunity!\",\n",
            " \"I'm a mysterious stranger with a captivating story. Text me and I'll share \"\n",
            " \"my past with you. I'm looking for love and adventure. Will you be my partner \"\n",
            " \"in crime? Text me now and let's make some memories!\",\n",
            " \"I'm a charming and handsome man with a heart of gold. Text me and I'll send \"\n",
            " \"you a message of love and affection. I'm looking for a soulmate to share my \"\n",
            " \"life with. Will you be mine? Text me now and let's start a beautiful journey \"\n",
            " 'together!',\n",
            " \"I'm a talented artist with a unique vision. Text me and I'll send you a \"\n",
            " \"preview of my latest masterpiece. I'm looking for a patron to support my art \"\n",
            " \"and help me achieve my dreams. Will you be my patron? Text me now and let's \"\n",
            " 'create something amazing together!',\n",
            " \"I'm a powerful sorcerer with magical abilities. Text me and I'll grant you a \"\n",
            " \"wish. I'm looking for a brave and worthy soul to join me in my quest. Will \"\n",
            " \"you be my ally in battle? Text me now and let's unleash our powers together!\",\n",
            " \"I'm a wealthy heiress with a hidden past. Text me and I'll reveal my \"\n",
            " \"secrets. I'm looking for a trustworthy companion to share my life with. Will \"\n",
            " \"you be my confidant and lover? Text me now and let's start a new chapter \"\n",
            " 'together!',\n",
            " 'Call now for the ultimate deal on luxury cars! Call 09061209465 now! Limited '\n",
            " \"time offer, only 1000 cars available! Don't miss out!\",\n",
            " \"You've won a lifetime supply of toothpaste! Call 08712466669 now to claim \"\n",
            " 'your prize!',\n",
            " 'Exclusive offer for you! Call 09061209465 now to get a free vacation to the '\n",
            " 'Maldives!',\n",
            " \"You've been selected for a free membership to the world's most prestigious \"\n",
            " 'golf club! Call 08712460324 now to claim your membership!',\n",
            " \"Call now to get a free subscription to the world's most popular gaming \"\n",
            " 'magazine! Call 09061209465 now to claim your free subscription!',\n",
            " \"You've won a free ticket to the biggest music festival in the world! Call \"\n",
            " '08712466669 now to claim your ticket!',\n",
            " \"Call now to get a free subscription to the world's most popular fashion \"\n",
            " 'magazine! Call 09061209465 now to claim your free subscription!',\n",
            " \"Call now to get a free subscription to the world's most popular sports \"\n",
            " 'magazine! Call 08712460324 now to claim your free subscription!',\n",
            " \"Call now to get a free subscription to the world's most popular cooking \"\n",
            " 'magazine! Call 09061209465 now to claim your free subscription!',\n",
            " \"Call now to get a free subscription to the world's most popular travel \"\n",
            " 'magazine! Call 08712466669 now to claim your free subscription!',\n",
            " 'Get your free VIP access to exclusive adult content at www.adults-only.com. '\n",
            " 'Call now for immediate registration!',\n",
            " 'Join our premium members club and receive unlimited access to the hottest '\n",
            " 'adult videos and photos. Sign up today and enjoy the best of the best!',\n",
            " 'Experience the ultimate in adult pleasure with our new line of high-quality '\n",
            " 'adult products. Order now and receive a complimentary sample with your '\n",
            " 'purchase!',\n",
            " 'Unlock the secrets of the adult world with our exclusive adult education '\n",
            " 'program. Enroll now and start your journey to a more fulfilling life!',\n",
            " 'Be the first to know about the latest adult-themed events and promotions. '\n",
            " 'Subscribe now and receive a free gift with your first purchase!',\n",
            " 'Discover the hidden depths of human sexuality with our comprehensive adult '\n",
            " 'education series. Sign up now and expand your horizons!',\n",
            " 'Unlock the power of adult pleasure with our new line of adult-themed '\n",
            " 'products. Order now and receive a free sample with your purchase!',\n",
            " 'Order now for exclusive deal! 2005 World Cup tickets for just £100. Text A, '\n",
            " 'B, or C to 83222. Hurry, offer ends soon!',\n",
            " 'Urgent! Your account balance is £600. Next question: Complete the landmark, '\n",
            " 'Big, A. Bob, B. Barry or C. Ben?. Text A, B or C to 83738. Good luck!',\n",
            " 'Limited time offer! Get 2003 Account Statement for shows 800 un-redeemed S. '\n",
            " 'I. M. points. Call 08719899230 Identifier Code: 41685 Expires 07/11/04.',\n",
            " 'Exclusive deal! 2005 World Cup tickets for just £100. Text A, B, or C to '\n",
            " '83222. Hurry, offer ends soon!',\n",
            " 'Call now for a chance to win a brand new iPhone! Call 08712466669 at '\n",
            " '10p/min. 2 stop texts call 08712460324(nat rate)',\n",
            " 'Monthly password for wap. mobsi.com is 391784. Use your wap phone not PC. '\n",
            " 'Call 08712466669 at 10p/min. 2 stop texts call 08712460324(nat rate)',\n",
            " 'PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. '\n",
            " 'points. Call 08715203694 Identifier Code: 40533 Expires 31/10/04',\n",
            " 'PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. '\n",
            " 'points. Call 08719899230 Identifier Code: 41685 Expires 07/11/04']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will add these examples in our training data and retrain the model.\n",
        "\n",
        "- we will create a data set with 'sms' and 'label'\n",
        "- add it to the training data\n",
        "- transform into tfidf vectors\n",
        "- build the model and test on the test data"
      ],
      "metadata": {
        "id": "Fe_mwr6gqqHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading in the train and test datasets created before\n",
        "train_sample = pd.read_csv('/content/train.csv')\n",
        "test_sample = pd.read_csv('/content/test.csv')\n",
        "print(train_sample.iloc[0:5],'\\n', test_sample.iloc[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVkwD0c0r-iT",
        "outputId": "15a7c2c8-cb42-4565-b549-478e55d189c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 sms  label\n",
            "0  Todays Vodafone numbers ending with 4882 are s...      1\n",
            "1  Yes. They replied my mail. I'm going to the ma...      0\n",
            "2            Super da:)good replacement for murali\\n      0\n",
            "3  Sorry I missed your call let's talk when you h...      1\n",
            "4  Todays Voda numbers ending 5226 are selected t...      1 \n",
            "                                                  sms  label\n",
            "0  \"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...      0\n",
            "1  Sorry i've not gone to that place. I.ll do so ...      0\n",
            "2            When are you going to ride your bike?\\n      0\n",
            "3  Daddy, shu shu is looking 4 u... U wan me 2 te...      0\n",
            "4                          What you did in  leave.\\n      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataframe to add to the train data\n",
        "df_to_add = pd.DataFrame({'sms': lines, 'label': [1] * len(lines)})\n",
        "print(df_to_add.iloc[0:5])\n",
        "# concat the df with the train data\n",
        "aug_train_sample = pd.concat([train_sample, df_to_add], ignore_index=True)\n",
        "print(\"before augmentation:\", len(train_sample), \"\\nafter augmentation:\", len(aug_train_sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZAcBYWPqpkC",
        "outputId": "f9571e06-868c-4b30-bcfb-42284e459931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 sms  label\n",
            "0  Hey there! I've got a once-in-a-lifetime deal ...      1\n",
            "1  Attention all O2 users! You've been selected f...      1\n",
            "2  URGENT! You've been chosen to receive a specia...      1\n",
            "3  Hello, dear friend! I'm reaching out to you wi...      1\n",
            "4  Attention all Vodafone users! You've been sele...      1\n",
            "before augmentation: 2006 \n",
            "after augmentation: 2047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize the data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df = 0.01)\n",
        "\n",
        "# Fit and transform the text data to create TF-IDF vectors\n",
        "train_tfidf_mat = vectorizer.fit_transform(aug_train_sample['sms'])\n",
        "test_tfidf_mat = vectorizer.transform(test_sample['sms'])\n",
        "\n",
        "print(train_tfidf_mat.shape, test_tfidf_mat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-EjKrIBqphJ",
        "outputId": "d320d176-0edf-41de-9923-40b05f99857f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2047, 216) (1338, 216)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrain model with augmented data\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the Multinomial Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "nb_classifier.fit(train_tfidf_mat, aug_train_sample['label'])\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = nb_classifier.predict(test_tfidf_mat)\n",
        "\n",
        "# Calculate the accuracy of the classifier\n",
        "accuracy = accuracy_score(test_sample['label'], y_pred)\n",
        "print(f\"Accuracy: {accuracy.round(2)}\")\n",
        "\n",
        "# Print the classification report\n",
        "report = classification_report(test_sample['label'], y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC-xxxwCqpZ0",
        "outputId": "74b7d101-59e6-4a91-dc3f-bd1d4ce8cae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1156\n",
            "           1       0.97      0.87      0.92       182\n",
            "\n",
            "    accuracy                           0.98      1338\n",
            "   macro avg       0.97      0.93      0.95      1338\n",
            "weighted avg       0.98      0.98      0.98      1338\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Some observations:\n",
        "- In the baseline model the recall was 82%, which improved to 87% with only 41 synthetically generated data-points! This improved the f1-score from 89% to 92%.\n",
        "- If we compare this with our previous approach, where we collected similar data (similar to FN cases), around 66 data points, we actually achieved the same f1-score of 92%.\n",
        "\n",
        "Therefore, LLM generated data can prove to be benefitial and even outperform normal data augmentation strategies if used wisely."
      ],
      "metadata": {
        "id": "mjPsaUbOunSq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69al3eKiqpW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LFsNlihopeh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6nMkkad1pee4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wf4XWy6bpeax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z4ksUx_apeYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xZQCUFrpYbR"
      },
      "outputs": [],
      "source": []
    }
  ]
}